# Deep-Check-Net---Chess-Model

An AlphaZero-style self-learning chess engine powered by deep reinforcement learning, MCTS, and a custom neural network called **DeepCheckNet**.

![Chessboard Banner](assets/banner.png) <!-- Optional visual -->

---

## â™Ÿï¸ Overview

This project implements a self-improving chess AI using modern reinforcement learning techniques:

* Self-play reinforcement learning
* Monte Carlo Tree Search (MCTS)
* Neural network policy & value prediction
* GUI for Human vs AI gameplay

Trained completely from scratch using only the game rules, with no human gameplay data.

---

## ğŸš€ Features

* `DeepCheckNet`: Residual CNN with separate policy and value heads
* MCTS enhanced with Dirichlet noise for exploration
* Full training loop with early stopping and learning rate scheduling
* Human vs Model and Model vs Model GUI via Pygame
* Game state, policy, and value saved in `.npz` for training

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ Auto_train_loop.py        # Self-play + training automation
â”œâ”€â”€ model.py                  # DeepCheckNet architecture
â”œâ”€â”€ Mcts_Engine.py            # MCTS with UCB and expansion
â”œâ”€â”€ Self_Play_Loop.py         # Self-play game generation
â”œâ”€â”€ Chess_Dataset_RL.py       # Dataset class for training
â”œâ”€â”€ chess_engine.py           # Terminal play with model
â”œâ”€â”€ gui_chess.py              # GUI game interface (pygame)
â”œâ”€â”€ parse_pgn.py              # Board/tensor conversion utils
â”œâ”€â”€ images/                   # Piece sprites for GUI
â”œâ”€â”€ saved_models/             # Trained models
â””â”€â”€ self_play_data.npz        # Training data from self-play
```

---

## ğŸ› ï¸ Installation

```bash
# Clone the repository
$ git clone https://github.com/yourusername/deepcheck-chess.git
$ cd deepcheck-chess

# Create virtual environment (optional but recommended)
$ python -m venv venv
$ source venv/bin/activate  # or .\venv\Scripts\activate on Windows

# Install dependencies
$ pip install -r requirements.txt
```

---

## ğŸ§  Training from Scratch

```bash
python Auto_train_loop.py
```

This will:

* Play N games of self-play
* Save data to `self_play_data.npz`
* Train on that data for several epochs
* Repeat, improving the model over time

Trained models are saved as `DeepCheckNet_model.pth`

---

## ğŸ® Play Against the Model

### CLI version:

```bash
python chess_engine.py
```

### GUI version:

```bash
python gui_chess.py
```

Choose Human vs Model or Model vs Model at runtime.

---

## ğŸ“Š Evaluation

* Early stopping based on validation loss
* Model only saved if performance improves
* Designed for continued self-improvement through self-play

---

## ğŸ“¦ Requirements

* Python 3.8+
* `torch`, `numpy`, `pygame`, `python-chess`

Install all dependencies with:

```bash
pip install -r requirements.txt
```

---

## ğŸ™ Acknowledgements

Inspired by:

* DeepMind's AlphaZero paper

Built with by Maaz Hasan
